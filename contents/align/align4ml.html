
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Alignment-based metrics in Machine Learning &#8212; Machine Learning for Time Series</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Dedicated neural-network architectures" href="../deep/intro.html" />
    <link rel="prev" title="Soft-DTW" href="softdtw.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  
  <h1 class="site-logo" id="site-title">Machine Learning for Time Series</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../foreword.html">
   Foreword
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="intro.html">
   Alignment-based metrics
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="dtw.html">
     Dynamic Time Warping
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="softdtw.html">
     Soft-DTW
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Alignment-based metrics in Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../deep/intro.html">
   Dedicated neural-network architectures
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        <a class="dropdown-buttons"
            href="../../_sources/contents/align/align4ml.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download notebook file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/contents/align/align4ml.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/rtavenar/ml4ts_ensai"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/rtavenar/ml4ts_ensai/issues/new?title=Issue%20on%20page%20%2Fcontents/align/align4ml.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/rtavenar/ml4ts_ensai/master?urlpath=tree/contents/align/align4ml.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#classification">
   Classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nearest-neighbors">
     Nearest neighbors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#global-alignment-kernel">
     Global Alignment Kernel
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clustering">
   Clustering
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#forecasting">
   Forecasting
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="alignment-based-metrics-in-machine-learning">
<h1>Alignment-based metrics in Machine Learning<a class="headerlink" href="#alignment-based-metrics-in-machine-learning" title="Permalink to this headline">¶</a></h1>
<p>When learning from non-aligned time series, being able to use alignment-based
metrics at the core of Machine Learning (ML) systems is key.</p>
<div class="section" id="classification">
<h2>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">¶</a></h2>
<div class="section" id="nearest-neighbors">
<h3>Nearest neighbors<a class="headerlink" href="#nearest-neighbors" title="Permalink to this headline">¶</a></h3>
<p>First, the similarity measures presented in this chapter can be used in
conjunction with nearest-neighbor classifiers.
To do so, it suffices to compute DTW (or any other time-series-specific)
between a test time series <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and all the series from the training
set, and then assign a label to <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> based on a voting strategy.</p>
<p>Note however that nearest neighbor searches in standard euclidean spaces are
usually fastened by smart indexing strategies that are no longer available when
using DTW in place of Euclidean distance.
A typical example is the use of triangular inequality to prune the set of
candidate neighbors (recall that DTW does not satisfy the triangular
inequality).</p>
<div class="tip dropdown admonition">
<p class="admonition-title">tslearn tip</p>
<p>To use these metrics for <span class="math notranslate nohighlight">\(k\)</span>-Nearest-Neighbor classification in <code class="docutils literal notranslate"><span class="pre">tslearn</span></code>,
the code is as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">knn_clf</span> <span class="o">=</span> <span class="n">KNeighborsTimeSeriesClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;dtw&quot;</span><span class="p">)</span>
<span class="n">knn_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted_labels</span> <span class="o">=</span> <span class="n">knn_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="global-alignment-kernel">
<span id="sec-gak"></span><h3>Global Alignment Kernel<a class="headerlink" href="#global-alignment-kernel" title="Permalink to this headline">¶</a></h3>
<p>Let us define the Global Alignment Kernel (GAK, <a class="bibtex reference internal" href="#cuturi2007kernel" id="id1">[CVBM07]</a>) as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-24ae4dee-e2c1-4ee7-ab0e-ae51d7acf04f">
<span class="eqno">(10)<a class="headerlink" href="#equation-24ae4dee-e2c1-4ee7-ab0e-ae51d7acf04f" title="Permalink to this equation">¶</a></span>\[\begin{equation}
k_\text{GA}^\gamma(\mathbf{x}, \mathbf{x}^\prime) =
    \exp{- \frac{\text{soft-}DTW^{\gamma}(\mathbf{x}, \mathbf{x}^\prime)}{\gamma}}
\end{equation}\]</div>
<p>Though this kernel is not proved to be positive semi-definite, authors claim
that, in practice, resulting Gram matrices happen to be psd in most of their
experiments, hence allowing this kernel to be used in standard kernel methods,
as discussed in the next section.
One typical use-case consists in using this kernel in Support
Vector Machines for classification.
When doing so, resulting support vectors are hence time series, as shown below:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;svg&#39;
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span>

<span class="kn">from</span> <span class="nn">tslearn.datasets</span> <span class="kn">import</span> <span class="n">CachedDatasets</span>
<span class="kn">from</span> <span class="nn">tslearn.preprocessing</span> <span class="kn">import</span> <span class="n">TimeSeriesScalerMinMax</span>
<span class="kn">from</span> <span class="nn">tslearn.svm</span> <span class="kn">import</span> <span class="n">TimeSeriesSVC</span>

<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">CachedDatasets</span><span class="p">()</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;Trace&quot;</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">TimeSeriesScalerMinMax</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">TimeSeriesScalerMinMax</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">TimeSeriesSVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s2">&quot;gak&quot;</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">n_classes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y_train</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">support_vectors</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">support_vectors_</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">y_train</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">n_classes</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Support vectors for class </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">cl</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">ts</span> <span class="ow">in</span> <span class="n">support_vectors</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ts</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/align4ml_2_0.svg" src="../../_images/align4ml_2_0.svg" /></div>
</div>
<p>Note that methods presented in this section straight-forwardly extend to
regression setups in
which the target variable is not a time series itself (for this specific case,
refer to our <a class="reference internal" href="#sec-forecasting"><span class="std std-ref">Forecasting</span></a> section).</p>
</div>
</div>
<div class="section" id="clustering">
<h2>Clustering<a class="headerlink" href="#clustering" title="Permalink to this headline">¶</a></h2>
<p>As shown above in our <a class="reference internal" href="intro.html#sec-intro-align"><span class="std std-ref">Alignment-based metrics</span></a> section, using standard clustering
algorithms can cause trouble when dealing with time-shifted time series.</p>
<p>In what follows, we discuss the use of Dynamic Time Warping at the core of
<span class="math notranslate nohighlight">\(k\)</span>-means clustering.</p>
<p>The <span class="math notranslate nohighlight">\(k\)</span>-means algorithm repeats the same two steps until convergence:</p>
<ol class="simple">
<li><p>assign all samples to their closest centroid ;</p></li>
<li><p>update centroids as the barycenters of the samples assigned to their
associated cluster.</p></li>
</ol>
<p>Step 1 only requires to compute distances.
Euclidean distance can hence
straight-forwardly be replaced by Dynamic Time Warping in order to get shift
invariance.
Step 2 requires the ability to compute barycenters.</p>
<p>These modifications allow to run a <span class="math notranslate nohighlight">\(k\)</span>-means algorithm with DTW as the core
metric:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tslearn.clustering</span> <span class="kn">import</span> <span class="n">TimeSeriesKMeans</span>
<span class="kn">from</span> <span class="nn">tslearn.datasets</span> <span class="kn">import</span> <span class="n">CachedDatasets</span>
<span class="kn">from</span> <span class="nn">tslearn.preprocessing</span> <span class="kn">import</span> <span class="n">TimeSeriesScalerMeanVariance</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Below is some data manipulation to make the dataset smaller</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">CachedDatasets</span><span class="p">()</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;Trace&quot;</span><span class="p">)</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">y_train</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">]</span>  <span class="c1"># Keep first 3 classes</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="c1"># Keep only 50 time series</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">TimeSeriesScalerMeanVariance</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:</span><span class="mi">50</span><span class="p">])</span>
<span class="n">sz</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># DBA-k-means</span>
<span class="n">dba_km</span> <span class="o">=</span> <span class="n">TimeSeriesKMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                          <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;dtw&quot;</span><span class="p">,</span>
                          <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                          <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dba_km</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">for</span> <span class="n">yi</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">yi</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">xx</span> <span class="ow">in</span> <span class="n">X_train</span><span class="p">[</span><span class="n">y_pred</span> <span class="o">==</span> <span class="n">yi</span><span class="p">]:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="s2">&quot;k-&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">dba_km</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">[</span><span class="n">yi</span><span class="p">]</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="s2">&quot;r-&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">sz</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span><span class="s1">&#39;Cluster </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">yi</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
             <span class="n">transform</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">transAxes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/align4ml_4_0.svg" src="../../_images/align4ml_4_0.svg" /></div>
</div>
<p>As a result, clusters gather time series of similar shapes, which is due to the
ability of Dynamic Time Warping (DTW) to deal with time shifts, as explained
above.
Second, cluster centers (aka centroids) are computed as the barycenters
with respect to DTW, hence
they allow to retrieve a sensible average shape whatever the temporal shifts
in the cluster.</p>
<p>Another option to deal with such time shifts is to rely on the kernel trick.
Indeed, the kernel <span class="math notranslate nohighlight">\(k\)</span>-means algorithm <a class="bibtex reference internal" href="#dhillon2004kernel" id="id2">[DGK04]</a>, that is
equivalent to a <span class="math notranslate nohighlight">\(k\)</span>-means
that would operate in the Reproducing Kernel Hilbert Space associated to the
chosen kernel, can be used in conjunction
with Global Alignment Kernel (GAK).</p>
<div class="figure align-default" id="kernel-kmeans">
<a class="reference internal image-reference" href="../../_images/kernel_kmeans.svg"><img alt="../../_images/kernel_kmeans.svg" src="../../_images/kernel_kmeans.svg" width="100%" /></a>
<p class="caption"><span class="caption-number">Fig. 3 </span><span class="caption-text">Kernel <span class="math notranslate nohighlight">\(k\)</span>-means clustering with Global Alignment Kernel.
Each subfigure represents series from a given cluster.</span><a class="headerlink" href="#kernel-kmeans" title="Permalink to this image">¶</a></p>
</div>
<p>A first significant difference (when compared to <span class="math notranslate nohighlight">\(k\)</span>-means) is that
cluster centers are never computed
explicitly, hence time series assignments to cluster are the only kind of
information available once the clustering is performed.</p>
<p>Second, one should note that the clusters generated by kernel-<span class="math notranslate nohighlight">\(k\)</span>-means,
while allowing for some time shifts, are still phase dependent
(see clusters 2 and 3 that differ in phase rather than in
shape).
This is because, contrary to DTW, Global Alignment Kernel is not invariant to
time shifts, as
discussed <a class="reference internal" href="softdtw.html#sec-softdtw"><span class="std std-ref">earlier</span></a> for the closely related soft-DTW.</p>
</div>
<div class="section" id="forecasting">
<span id="sec-forecasting"></span><h2>Forecasting<a class="headerlink" href="#forecasting" title="Permalink to this headline">¶</a></h2>
<p>As discussed earlier, soft-DTW is differentiable with respect to its inputs.
This is especially useful for forecasting tasks in which prediction is to be
made for multiple time steps (<em>multi-step ahead forecasting</em>)<a class="footnote-reference brackets" href="#structpred" id="id3">1</a>.
Indeed, in this context, soft-DTW can be used in place of a standard Mean
Squared Error (MSE) loss in order to better take time shifts into account.</p>
<p>This is done, for example, in the seminal paper by Cuturi and Blondel
<a class="bibtex reference internal" href="#cuturi2017soft" id="id4">[CB17]</a>:</p>
<div class="figure align-default" id="forecasting-cuturi-blondel">
<a class="reference internal image-reference" href="../../_images/forecasting_cuturi_blondel.png"><img alt="../../_images/forecasting_cuturi_blondel.png" src="../../_images/forecasting_cuturi_blondel.png" style="width: 50%;" /></a>
<p class="caption"><span class="caption-number">Fig. 4 </span><span class="caption-text">Using soft-DTW in place of a standard Euclidean loss for forecasting.
This Figure is taken from <a class="bibtex reference internal" href="#cuturi2017soft" id="id5">[CB17]</a>.</span><a class="headerlink" href="#forecasting-cuturi-blondel" title="Permalink to this image">¶</a></p>
</div>
<p>An alternative differentiable loss (DILATE) is introduced in
<a class="bibtex reference internal" href="#vincent2019shape" id="id6">[LGT19]</a> that relies on soft-DTW and penalizes
de-synchronized alignments.
This is done by introducing an additional penalty to the loss to be optimized,
which is the dot product between a “soft-mask matrix” <span class="math notranslate nohighlight">\(\Omega\)</span>
and the computed soft path matrix <span class="math notranslate nohighlight">\(A_\gamma\)</span>, which tends to favor diagonal
matches :</p>
<div class="amsmath math notranslate nohighlight" id="equation-cb5587f6-f543-4783-b0f8-33f3e661032f">
<span class="eqno">(11)<a class="headerlink" href="#equation-cb5587f6-f543-4783-b0f8-33f3e661032f" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathcal{L}_\text{reg} = \mathcal{L}_\text{soft-DTW} + \langle \Omega , A_\gamma \rangle .
\end{equation}\]</div>
<p>The <span class="math notranslate nohighlight">\(\Omega\)</span> matrix typically looks like:</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">positions</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="c1">#      ↓ column vector of positions   ↓ row vector of positions</span>
<span class="n">mat</span> <span class="o">=</span> <span class="p">(</span><span class="n">positions</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>   <span class="o">-</span> <span class="n">positions</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)))</span> <span class="o">**</span> <span class="mi">2</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/align4ml_6_0.svg" src="../../_images/align4ml_6_0.svg" /></div>
</div>
<p>As a result, the DILATE method allows to both better model shape matching than
MSE and better localize shapes than soft-DTW:</p>
<div class="figure align-default" id="forecasting-le-guen">
<a class="reference internal image-reference" href="../../_images/forecasting_le_guen.png"><img alt="../../_images/forecasting_le_guen.png" src="../../_images/forecasting_le_guen.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-number">Fig. 5 </span><span class="caption-text">Comparison between MSE, soft-DTW (denoted <span class="math notranslate nohighlight">\(DTW_\gamma\)</span>) and DILATE as loss
functions for forecasting tasks.
This Figure is taken from <a class="bibtex reference internal" href="#vincent2019shape" id="id7">[LGT19]</a>.</span><a class="headerlink" href="#forecasting-le-guen" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">¶</a></h2>
<p>In this part of the course, we have presented similarity measures for time
series that aim to
tackle time shift invariance (a.k.a. temporal localization invariance) and their
use at the core of various machine learning models.</p>
<p>Dynamic Time Warping is probably the most well-known measures among those
presented here.
We have shown how to use it in standard classification models as well as for
<span class="math notranslate nohighlight">\(k\)</span>-means clustering, in which case a notion of barycenter has to be defined.
We have also presented one of its strongest limitations which is its
non-differentiability, which has led to the introduction of a soft variant
that can hence be used as a loss (for structured prediction settings) in
neural networks.</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-contents/align/align4ml-0"><dl class="citation">
<dt class="bibtex label" id="cuturi2017soft"><span class="brackets">CB17</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id5">2</a>)</span></dt>
<dd><p>Marco Cuturi and Mathieu Blondel. Soft-DTW: a differentiable loss function for time-series. In <em>Proceedings of the International Conference on Machine Learning</em>, 894–903. JMLR. org, 2017.</p>
</dd>
<dt class="bibtex label" id="cuturi2007kernel"><span class="brackets"><a class="fn-backref" href="#id1">CVBM07</a></span></dt>
<dd><p>Marco Cuturi, Jean-Philippe Vert, Oystein Birkenes, and Tomoko Matsui. A kernel for time series based on global alignments. In <em>Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing</em>, volume 2, II–413. IEEE, 2007.</p>
</dd>
<dt class="bibtex label" id="dhillon2004kernel"><span class="brackets"><a class="fn-backref" href="#id2">DGK04</a></span></dt>
<dd><p>Inderjit S Dhillon, Yuqiang Guan, and Brian Kulis. Kernel k-means: spectral clustering and normalized cuts. In <em>Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data mining</em>, 551–556. 2004.</p>
</dd>
<dt class="bibtex label" id="vincent2019shape"><span class="brackets">LGT19</span><span class="fn-backref">(<a href="#id6">1</a>,<a href="#id7">2</a>)</span></dt>
<dd><p>Vincent Le Guen and Nicolas Thome. Shape and time distortion loss for training deep time series forecasting models. In <em>Neural Information Processing Systems</em>, 4189–4201. 2019.</p>
</dd>
</dl>
</p>
<hr class="docutils" />
<dl class="footnote brackets">
<dt class="label" id="structpred"><span class="brackets"><a class="fn-backref" href="#id3">1</a></span></dt>
<dd><p>This problem is an instance of a more general class of problems
known as structured prediction problems, in which the target variable
(to be predicted) has a specific structure (time series, graph, <em>etc.</em>).</p>
</dd>
</dl>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./contents/align"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="softdtw.html" title="previous page">Soft-DTW</a>
    <a class='right-next' id="next-link" href="../deep/intro.html" title="next page">Dedicated neural-network architectures</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Romain Tavenard<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>